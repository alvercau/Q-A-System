{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import en_core_web_sm\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.externals import joblib\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The sentence database\n",
    "\n",
    "The sentence database will have one doc per sentence, which has the following structure:\n",
    "\n",
    "        {\n",
    "        'sentence': sentence,\n",
    "        'paper_id' : id from origin paper in paper DB,\n",
    "        'score': sentence_score predicted by classification model,\n",
    "        'keywords: list of k_important words\n",
    "        'similar_sentences: ID1, ID2, ...\n",
    "        'type_entity': [type, word]\n",
    "        }\n",
    "        \n",
    "__To do__:  \n",
    "1. Calculate features for all sentences.\n",
    "2. Calculate score for each sentence.\n",
    "4. Construct list of keywords in sentence.\n",
    "5. construct list of entity type for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.lingbuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# db.create_collection('sentences')\n",
    "# db.create_collection('keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "papers = db.get_collection('papers')\n",
    "sentences = db.get_collection('sentences')\n",
    "keywords = db.get_collection('keywords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_papers = pd.DataFrame(columns=['paperID', 'paper'])\n",
    "for doc in papers.find({'paper':{'$exists': True}}):\n",
    "    df_papers = df_papers.append({'paperID': doc['_id'], 'paper': doc['paper']}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperID</th>\n",
       "      <th>paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>598b44c407d7df07719383e2</td>\n",
       "      <td>ANALYTIC PASSIVES IN CZECH    Ludmila Veselovs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>598b44c407d7df07719383e5</td>\n",
       "      <td>UNIVERSAL DP-ANALYSIS IN ARTICLELESS LANGUAGE:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>598b44c407d7df07719383e8</td>\n",
       "      <td>Strong Pronominals in ASL and LSF*   Philippe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>598b44c407d7df07719383f0</td>\n",
       "      <td>THE UNIVERSITY OF CHICAGO  INFLECTIONAL DEPEND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>598b44c407d7df07719383fc</td>\n",
       "      <td>Multiple Sluicing, Scope, and Superiority: Con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    paperID                                              paper\n",
       "0  598b44c407d7df07719383e2  ANALYTIC PASSIVES IN CZECH    Ludmila Veselovs...\n",
       "1  598b44c407d7df07719383e5  UNIVERSAL DP-ANALYSIS IN ARTICLELESS LANGUAGE:...\n",
       "2  598b44c407d7df07719383e8  Strong Pronominals in ASL and LSF*   Philippe ...\n",
       "3  598b44c407d7df07719383f0  THE UNIVERSITY OF CHICAGO  INFLECTIONAL DEPEND...\n",
       "4  598b44c407d7df07719383fc  Multiple Sluicing, Scope, and Superiority: Con..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_papers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "top_k_words = joblib.load('top_k_words')\n",
    "authors = joblib.load('authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_k_important(sent):\n",
    "    count = 0\n",
    "    keywords = []\n",
    "    for w in sent:\n",
    "        if w.lower_ in top_k_words:\n",
    "            count+=1\n",
    "            keywords.append(w.lower_)\n",
    "    return count, keywords\n",
    "\n",
    "def eliminate_non_english_words(s):\n",
    "    \"\"\"takes list of words and eliminates all words that contain non-english characters, digits or punctuation\"\"\"\n",
    "    english_words = []\n",
    "    for word in s:\n",
    "        if word.lower() in authors:\n",
    "            english_words.append(word)\n",
    "        else: \n",
    "            try:\n",
    "                word.encode(encoding='utf-8').decode('ascii')\n",
    "                # if re.sub('-', '', word).isalpha():\n",
    "                    # english_words.append(re.sub('[%s]' % re.escape(string.punctuation), '', word))\n",
    "                word = re.sub('[%s]' % re.escape(string.punctuation), '', word)\n",
    "                if word.isalpha():\n",
    "                    english_words.append(word) \n",
    "            except UnicodeDecodeError:\n",
    "                pass\n",
    "    return ' '.join(english_words)\n",
    "\n",
    "def calculate_named_entities(sent):\n",
    "    count = 0\n",
    "    entities = []\n",
    "    for ent in sent.ents:\n",
    "        count+=1\n",
    "        entities.append((ent.label_, ent.text))\n",
    "    return count, entities\n",
    "\n",
    "def calculate_pos(sent):\n",
    "    n = 0\n",
    "    v = 0\n",
    "    a = 0\n",
    "    for w in sent:\n",
    "        if w.pos_ == 'VERB':\n",
    "            v+=1\n",
    "        if w.pos_ == 'ADJ':\n",
    "            a += 1\n",
    "        if w.pos_ == 'NOUN':\n",
    "            n+=1\n",
    "    return n, v, a\n",
    "\n",
    "def calculate_upper(sent):\n",
    "    counter = -1\n",
    "    if sent[0].prefix_.islower():\n",
    "        return counter\n",
    "    else:\n",
    "        for w in sent:\n",
    "            if not w.is_lower:\n",
    "                counter += 1\n",
    "        return counter    \n",
    "\n",
    "def calculate_and_to_db(df):\n",
    "    \"\"\"takes a df, calculates features, score, tfidf-vector and stores in MongoDB\"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        posi = 0\n",
    "        for sent in nlp(row['paper']).sents:\n",
    "            _id = sentences.insert({'sentence': str(sent), 'paperID': row['paperID']})\n",
    "            out = [len(list(sent))]\n",
    "            upper = calculate_upper(sent)\n",
    "            sent = nlp(eliminate_non_english_words(str(sent).split()))\n",
    "            named_entities, type_entity = calculate_named_entities(sent)\n",
    "            k_important, keywords = count_k_important(sent)\n",
    "            pos = 100/len(list(nlp(row['paper']).sents))*posi\n",
    "            nouns, verbs, adjectives = calculate_pos(sent)\n",
    "            out+=[named_entities, k_important, pos, upper, nouns, verbs, adjectives]\n",
    "            # probability of being informative\n",
    "            score = scorer.predict_proba(out)[0][1]\n",
    "            sentences.update_one({'_id': _id}, {'$set': {'type_entity': type_entity, 'keywords': keywords, \n",
    "                                                                  'score': score}})\n",
    "            posi += 1\n",
    "            \n",
    "            # no match on sentence because I have two different instances of sentence.\n",
    "            # drop all docs. retrieve the _id when doc is created and match on that one.\n",
    "            \n",
    "            \n",
    "num_partitions = 3 #number of partitions to split dataframe\n",
    "num_cores = 3 #number of cores on your machine\n",
    "\n",
    "def parallelize_dataframe(df, func):\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/pymongo/topology.py:145: UserWarning: MongoClient opened before fork. Create MongoClient with connect=False, or create client after forking. See PyMongo's documentation for details: http://api.mongodb.org/python/current/faq.html#pymongo-fork-safe>\n",
      "  \"MongoClient opened before fork. Create MongoClient \"\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/pymongo/topology.py:145: UserWarning: MongoClient opened before fork. Create MongoClient with connect=False, or create client after forking. See PyMongo's documentation for details: http://api.mongodb.org/python/current/faq.html#pymongo-fork-safe>\n",
      "  \"MongoClient opened before fork. Create MongoClient \"\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/pymongo/topology.py:145: UserWarning: MongoClient opened before fork. Create MongoClient with connect=False, or create client after forking. See PyMongo's documentation for details: http://api.mongodb.org/python/current/faq.html#pymongo-fork-safe>\n",
      "  \"MongoClient opened before fork. Create MongoClient \"\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-146-45d5c507bafd>\", line 70, in calculate_and_to_db\n",
      "    pos = 100/len(list(nlp(row['paper']).sents))*posi\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/site-packages/spacy/language.py\", line 341, in __call__\n",
      "    doc = self.make_doc(text)\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/site-packages/spacy/language.py\", line 315, in <lambda>\n",
      "    self.make_doc = lambda text: self.tokenizer(text)\n",
      "  File \"spacy/tokenizer.pyx\", line 155, in spacy.tokenizer.Tokenizer.__call__ (spacy/tokenizer.cpp:5351)\n",
      "  File \"spacy/tokenizer.pyx\", line 207, in spacy.tokenizer.Tokenizer._tokenize (spacy/tokenizer.cpp:6087)\n",
      "  File \"spacy/tokenizer.pyx\", line 281, in spacy.tokenizer.Tokenizer._attach_tokens (spacy/tokenizer.cpp:7156)\n",
      "  File \"spacy/vocab.pyx\", line 252, in spacy.vocab.Vocab.get (spacy/vocab.cpp:7012)\n",
      "  File \"spacy/vocab.pyx\", line 279, in spacy.vocab.Vocab._new_lexeme (spacy/vocab.cpp:7465)\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/site-packages/spacy/language.py\", line 177, in <lambda>\n",
      "    attrs.LOWER: lambda string: string.lower(),\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-018dca3d3ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparallelize_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_papers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_and_to_db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-146-45d5c507bafd>\u001b[0m in \u001b[0;36mparallelize_dataframe\u001b[0;34m(df, func)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mdf_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_partitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         '''\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aleksandra/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aleksandra/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-146-45d5c507bafd>\", line 70, in calculate_and_to_db\n",
      "    pos = 100/len(list(nlp(row['paper']).sents))*posi\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/site-packages/spacy/language.py\", line 350, in __call__\n",
      "    proc(doc)\n",
      "  File \"spacy/syntax/parser.pyx\", line 205, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:7682)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"<ipython-input-146-45d5c507bafd>\", line 70, in calculate_and_to_db\n",
      "    pos = 100/len(list(nlp(row['paper']).sents))*posi\n",
      "  File \"/home/aleksandra/anaconda3/lib/python3.6/site-packages/spacy/language.py\", line 350, in __call__\n",
      "    proc(doc)\n",
      "  File \"spacy/syntax/parser.pyx\", line 205, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:7682)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "parallelize_dataframe(df_papers, calculate_and_to_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The classification model that gives probabilities\n",
    "scorer = joblib.load('scorer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperID</th>\n",
       "      <th>paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>598b44c407d7df07719383e2</td>\n",
       "      <td>ANALYTIC PASSIVES IN CZECH    Ludmila Veselovs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>598b44c407d7df07719383e5</td>\n",
       "      <td>UNIVERSAL DP-ANALYSIS IN ARTICLELESS LANGUAGE:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    paperID                                              paper\n",
       "0  598b44c407d7df07719383e2  ANALYTIC PASSIVES IN CZECH    Ludmila Veselovs...\n",
       "1  598b44c407d7df07719383e5  UNIVERSAL DP-ANALYSIS IN ARTICLELESS LANGUAGE:..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_papers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculate_and_to_db(df_papers.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('59a85acdb18b146ddb84ff2b'), 'sentence': 'To Appear in H. Harley ed.', 'paperID': ObjectId('598b44c407d7df0771938b4e'), 'type_entity': [['ORG', 'Harley']], 'keywords': ['appear', 'h', 'harley', 'ed'], 'score': 0.9812410356893851}\n",
      "{'_id': ObjectId('59a85aceb18b146ddb84ff2c'), 'sentence': 'The Proceedings of the Penn/MIT Workshop on Aspect, Argument  Structure, and Events, May 1997, MITWPL  Voice Systems and the Syntax/Morphology Interface\\x00  David Embick, University of Pennsylvania/MIT  1  ', 'paperID': ObjectId('598b44c407d7df0771938b4e'), 'type_entity': [['ORG', 'the PennMIT Workshop'], ['ORG', 'Aspect Argument Structure'], ['ORG', 'David Embick University of PennsylvaniaMIT']], 'keywords': ['proceedings', 'workshop', 'aspect', 'argument', 'structure', 'events', 'mitwpl', 'voice', 'systems', 'syntaxmorphology', 'david', 'embick', 'university'], 'score': 0.11010114041868405}\n",
      "{'_id': ObjectId('59a85aceb18b146ddc84ff2b'), 'sentence': 'Polish Stress: looking for phonetic evidence of a bidirectional system   Luiza Newlin- Łukowicz   New York University   luiza.lukowicz@nyu.edu      Note: This is a pre-publication manuscript.', 'paperID': ObjectId('598b44c407d7df077193965e'), 'type_entity': [['NORP', 'Polish'], ['EVENT', 'Luiza Newlin New York University luizalukowicznyuedu Note']], 'keywords': ['polish', 'stress', 'looking', 'phonetic', 'evidence', 'bidirectional', 'luiza', 'new', 'york', 'university', 'note', 'prepublication', 'manuscript'], 'score': 0.5999068467428688}\n",
      "{'_id': ObjectId('59a85acfb18b146dda84ff2b'), 'sentence': 'ANALYTIC PASSIVES IN CZECH    Ludmila Veselovská & Petr Karlík   INTRODUCTION: DEFINING THE PROBLEM   Like other languages, Czech also has pairs of sentences clearly related both in their  form and in their meaning.', 'paperID': ObjectId('598b44c407d7df07719383e2'), 'type_entity': [['NORP', 'Czech']], 'keywords': ['analytic', 'passives', 'czech', 'ludmila', 'veselovská', 'petr', 'introduction', 'defining', 'problem', 'like', 'languages', 'czech', 'pairs', 'sentences', 'clearly', 'related', 'form', 'meaning'], 'score': 0.8063238473917833}\n",
      "{'_id': ObjectId('59a85acfb18b146ddb84ff2d'), 'sentence': 'Introduction  The topic of this paper is the manner in which syntactic voice alternations (and syntactic conﬁgurations more generally) relate to voice morphology, and the implications of this for theories of voice and theories of morphology/syntax in- teractions.', 'paperID': ObjectId('598b44c407d7df0771938b4e'), 'type_entity': [], 'keywords': ['introduction', 'topic', 'paper', 'manner', 'syntactic', 'voice', 'alternations', 'syntactic', 'generally', 'relate', 'voice', 'morphology', 'implications', 'theories', 'voice', 'theories', 'morphologysyntax', 'teractions'], 'score': 0.8883947763032296}\n"
     ]
    }
   ],
   "source": [
    "for doc in sentences.find()[:5]:\n",
    "    print(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
