{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from pymongo import MongoClient\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from seaborn import plt\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification to optimize weights of the features\n",
    "\n",
    "Train logistic regression model based on sentences in abstracts (1) and sentences in examples (0)\n",
    "Retain the optimal parameters to calculate sentence scores. Make sure that the classses aren't contiguous, shuffle the data!  \n",
    "\n",
    "Question: what would the score of a sentence look like exactly? The probas of the model? Is Logisitc Regression the only option?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joblib.load('data_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>length</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>k_important</th>\n",
       "      <th>position</th>\n",
       "      <th>upper</th>\n",
       "      <th>nouns</th>\n",
       "      <th>verbs</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The paper will argue for the existence of null...</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I will present a set of paradoxical cases in w...</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I will suggest that the domain of locality rel...</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specifically, it will be proposed that a resum...</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The CCRC will explain why resumptive dependenc...</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  length  named_entities  \\\n",
       "0  The paper will argue for the existence of null...      63               4   \n",
       "1  I will present a set of paradoxical cases in w...      32               1   \n",
       "2  I will suggest that the domain of locality rel...      29               3   \n",
       "3  Specifically, it will be proposed that a resum...      31               3   \n",
       "4  The CCRC will explain why resumptive dependenc...      34               7   \n",
       "\n",
       "   k_important  position  upper  nouns  verbs  adjectives  category  \n",
       "0           28       0.0     14     13      9           6         1  \n",
       "1           13      20.0      4      8      4           3         1  \n",
       "2           15      40.0      4      4      5           4         1  \n",
       "3           12      60.0     13      3      6           1         1  \n",
       "4           15      80.0      9      4      5           3         1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "Purpose: \n",
    "* deal with outliers\n",
    "* If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n",
    "* Normalization is the process of scaling individual samples to have unit norm.\n",
    "\n",
    "# Classification\n",
    "\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.category\n",
    "X = data.drop(['category', 'sentence'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37361, 8)\n",
      "(37361,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "mod = make_pipeline(Normalizer(), LogisticRegression(n_jobs=-1))\n",
    "mod.fit(X_train, y_train)\n",
    "y_pred = mod.predict(X_test)\n",
    "cr = metrics.classification_report(y_test, y_pred, labels=list(np.unique(y_train)))\n",
    "acs = metrics.accuracy_score(y_test, y_pred)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=list(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839096456482\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.80      0.84      4785\n",
      "          1       0.81      0.88      0.84      4556\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(acs)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: of all the ones that I classified as positive, how many really were?  \n",
    "Recall: of all the ones that were positive in reality, how many did I find?  \n",
    "\n",
    "Useless sentences are not identified as well as informative sentences; useless sentences are more likely to be really useless than informative sentences.  \n",
    "Bref: the model does well at identifying informative sentences, it does slightly worse on identifying uselss sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(steps=[('normalizer', Normalizer(copy=True, norm='l2')), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAAGOCAYAAAD4lyiYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8H9XxOeG4xZrVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f39f1574cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, list(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag']}\n",
    "X_train_normal = Normalizer().fit_transform(X_train)\n",
    "X_test_normal = Normalizer().fit_transform(X_test)\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid=parameters, n_jobs=-1)\n",
    "clf.fit(X_train_normal, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set: \n",
      "\n",
      "{'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set: \\n\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set: \n",
      "\n",
      "{'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'penalty':['l2', 'l1']}\n",
    "X_train_normal = Normalizer().fit_transform(X_train)\n",
    "X_test_normal = Normalizer().fit_transform(X_test)\n",
    "clf = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid=parameters, n_jobs=-1)\n",
    "clf.fit(X_train_normal, y_train)\n",
    "print(\"Best parameters set found on development set: \\n\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = make_pipeline(Normalizer(), LogisticRegression(solver='newton-cg', n_jobs=-1))\n",
    "mod.fit(X_train, y_train)\n",
    "y_pred = mod.predict(X_test)\n",
    "cr = metrics.classification_report(y_test, y_pred, labels=list(np.unique(y_train)))\n",
    "acs = metrics.accuracy_score(y_test, y_pred)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=list(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.838882346644\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.80      0.84      4785\n",
      "          1       0.81      0.88      0.84      4556\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(acs)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same result as with the liblinear solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod = LogisticRegression(solver='liblinear', penalty='l1', n_jobs=-1)\n",
    "mod.fit(X_train_normal, y_train)\n",
    "y_pred = mod.predict(X_test_normal)\n",
    "cr = metrics.classification_report(y_test, y_pred, labels=list(np.unique(y_train)))\n",
    "acs = metrics.accuracy_score(y_test, y_pred)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=list(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-12.75552024,  10.7071918 ,  32.97250852,  -1.06255969,\n",
       "         -5.54427811,   0.        ,   3.33105565,   2.19126917]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841665774542\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.81      0.84      4785\n",
      "          1       0.81      0.88      0.84      4556\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(acs)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always get the same results, so let's just go for the default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83940043,  0.84380205,  0.84249346,  0.84594337,  0.847133  ])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=5, test_size=0.3)\n",
    "cross_val_score(mod, X_train_normal, y_train, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('norm', Normalizer()), ('poly', PolynomialFeatures()), ('log', LogisticRegression())])\n",
    "parameters = {'poly__degree': list(range(7)), 'log__solver':['newton-cg', 'lbfgs', 'liblinear', 'sag']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('norm', Normalizer(copy=True, norm='l2')), ('poly', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('log', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'poly__degree': [0, 1, 2, 3, 4, 5, 6], 'log__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid=parameters, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set: \n",
      "\n",
      "{'log__solver': 'newton-cg', 'poly__degree': 6}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set: \\n\")\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.849\n",
      "Best parameters set:\n",
      "\tlog__solver: 'newton-cg'\n",
      "\tpoly__degree: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much of an improvement. Let's do a cross-val on the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('norm', Normalizer()), ('poly', PolynomialFeatures(degree=6)), \n",
    "                     ('log', LogisticRegression(solver='newton-cg', n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.85212943,  0.84772781,  0.84308827,  0.84963122,  0.84356412])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=5, test_size=0.3)\n",
    "cross_val_score(pipeline, X_train, y_train, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_fin = Pipeline([('norm', Normalizer()), ('poly', PolynomialFeatures(degree=6)), \n",
    "                     ('log', LogisticRegression(solver='newton-cg', n_jobs=-1))])\n",
    "log_fin.fit(X_train, y_train)\n",
    "y_pred = log_fin.predict(X_test)\n",
    "cr = metrics.classification_report(y_test, y_pred, labels=list(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.82      0.85      4785\n",
      "          1       0.82      0.87      0.85      4556\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are slightly better on recall than with the basic model, but the model is way more complex. Is it worth it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = make_pipeline(Normalizer(), RandomForestClassifier(n_jobs = -1))\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "cr = metrics.classification_report(y_test, y_pred, labels=list(np.unique(y_train)))\n",
    "acs = metrics.accuracy_score(y_test, y_pred)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=list(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.85      0.85      4785\n",
      "          1       0.85      0.84      0.84      4556\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9341\n",
      "\n",
      "0.848624344289\n"
     ]
    }
   ],
   "source": [
    "print(cr)\n",
    "print(acs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': range(5, 20), 'min_samples_split': range(2, 10, 2)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth': range(5, 20), 'min_samples_split' : range(2, 10, 2)}\n",
    "clf_rf = GridSearchCV(RandomForestClassifier(n_estimators = 100), parameters, n_jobs = -1)\n",
    "clf_rf.fit(X_train_normal, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set: \n",
      "\n",
      "{'max_depth': 17, 'min_samples_split': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set: \\n\")\n",
    "print(clf_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=17, min_samples_split=8, n_estimators=100, n_jobs=-1)\n",
    "rf.fit(X_train_normal, y_train)\n",
    "y_pred = rf.predict(X_test_normal)\n",
    "cr = metrics.classification_report(y_test, y_pred, labels=list(np.unique(y_train)))\n",
    "acs = metrics.accuracy_score(y_test, y_pred)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=list(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('named_entities', 0.041450878462891659),\n",
       " ('verbs', 0.051165834861816348),\n",
       " ('adjectives', 0.072280844601537012),\n",
       " ('nouns', 0.074669890591475399),\n",
       " ('length', 0.11606623047937072),\n",
       " ('position', 0.17180271002872657),\n",
       " ('upper', 0.22508163769671885),\n",
       " ('k_important', 0.24748197327746357)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(X_train.columns, rf.feature_importances_)), key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.84      0.86      4785\n",
      "          1       0.84      0.88      0.86      4556\n",
      "\n",
      "avg / total       0.86      0.86      0.86      9341\n",
      "\n",
      "0.859758055883\n"
     ]
    }
   ],
   "source": [
    "print(cr)\n",
    "print(acs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests does slightly better than Logistic Regression.\n",
    "\n",
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = make_pipeline(Normalizer(), BernoulliNB())\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = mod.predict(X_test)\n",
    "cr = metrics.classification_report(y_test, y_pred, labels=list(np.unique(y_train)))\n",
    "acs = metrics.accuracy_score(y_test, y_pred)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels=list(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.96      0.78      4785\n",
      "          1       0.92      0.49      0.63      4556\n",
      "\n",
      "avg / total       0.79      0.73      0.71      9341\n",
      "\n",
      "0.727438175784\n"
     ]
    }
   ],
   "source": [
    "print(cr)\n",
    "print(acs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one sucks..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aleksandra/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xg = make_pipeline(Normalizer(), XGBClassifier())\n",
    "xg.fit(X_train, y_train)\n",
    "y_pred = xg.predict(X_test)\n",
    "cr = metrics.classification_report(y_test, y_pred, labels=list(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.83      0.85      4785\n",
      "          1       0.83      0.89      0.86      4556\n",
      "\n",
      "avg / total       0.86      0.86      0.86      9341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=0.5),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': range(5, 20)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth': range(5, 20)}\n",
    "clf_xg = GridSearchCV(XGBClassifier(subsample=0.5), parameters, n_jobs = -1)\n",
    "clf_xg.fit(X_train_normal, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set: \n",
      "\n",
      "{'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set: \\n\")\n",
    "print(clf_xg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xg = XGBClassifier(max_depth=6)\n",
    "xg.fit(X_train_normal, y_train)\n",
    "y_pred = xg.predict(X_test_normal)\n",
    "cr = metrics.classification_report(y_test, y_pred, labels=list(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.83      0.86      4785\n",
      "          1       0.83      0.89      0.86      4556\n",
      "\n",
      "avg / total       0.86      0.86      0.86      9341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('named_entities', 0.082943641),\n",
       " ('adjectives', 0.091311842),\n",
       " ('nouns', 0.099680036),\n",
       " ('verbs', 0.11149397),\n",
       " ('position', 0.11666256),\n",
       " ('upper', 0.12576914),\n",
       " ('length', 0.17597835),\n",
       " ('k_important', 0.19616047)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(X_train.columns, xg.feature_importances_)), key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison with RF, we get more or less the same results. RF does slightly better though. Same feature importances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "We always get more or less the same results. I will just stick to the basic Logistic Regression model with normalization. It's simple, fast, gives me weights and probabilities. It's what I need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And the winner is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(Normalizer(), LogisticRegression(n_jobs=-1))\n",
    "fitted = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probas = pd.DataFrame(fitted.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049073</td>\n",
       "      <td>0.950927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.154227</td>\n",
       "      <td>0.845773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034586</td>\n",
       "      <td>0.965414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.432618</td>\n",
       "      <td>0.567382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.178678</td>\n",
       "      <td>0.821322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.049073  0.950927\n",
       "1  0.154227  0.845773\n",
       "2  0.034586  0.965414\n",
       "3  0.432618  0.567382\n",
       "4  0.178678  0.821322"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scorer']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'scorer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04907286,  0.95092714])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted.predict_proba(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
